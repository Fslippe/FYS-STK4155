\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\babel@aux{english}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Splitting and scaling of data}{6}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Mean squared error and R squared}{7}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Bias-variance trade-off}{7}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Cross validation}{9}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A visualization of the splits of the data performed in cross validation. Here we see 4 $k$-folds which gives a total of 4 splits and iterations.   \url  {https://scikit-learn.org/stable/modules/cross_validation.html}\relax }}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:k_fold}{{1}{9}{A visualization of the splits of the data performed in cross validation. Here we see 4 $k$-folds which gives a total of 4 splits and iterations. \\ \url {https://scikit-learn.org/stable/modules/cross_validation.html}\relax }{figure.caption.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Study of $\lambda $ dependence for ridge and lasso regression}{10}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Study of topography data}{10}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Franke funtion}{11}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}OLS scaling of data}{11}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{fig:}{{2a}{11}{$MSE$\relax }{figure.caption.3}{}}
\newlabel{sub@fig:}{{a}{11}{$MSE$\relax }{figure.caption.3}{}}
\newlabel{fig:}{{2b}{11}{$R^2$\relax }{figure.caption.3}{}}
\newlabel{sub@fig:}{{b}{11}{$R^2$\relax }{figure.caption.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of MSE and $R^2$ between scaled and non-scaled data\relax }}{11}{figure.caption.3}\protected@file@percent }
\newlabel{fig:compare_scale}{{2}{11}{Comparison of MSE and $R^2$ between scaled and non-scaled data\relax }{figure.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}OLS MSE and $R^2$}{11}{subsubsection.3.1.2}\protected@file@percent }
\newlabel{fig:}{{3a}{12}{$MSE$\relax }{figure.caption.4}{}}
\newlabel{sub@fig:}{{a}{12}{$MSE$\relax }{figure.caption.4}{}}
\newlabel{fig:}{{3b}{12}{$R^2$\relax }{figure.caption.4}{}}
\newlabel{sub@fig:}{{b}{12}{$R^2$\relax }{figure.caption.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces plots of MSE and $R^2$ for the franke function for an error $\epsilon \sim N(0, \sigma ^2)$ with $\sigma =0.2$ and 31 points in each direction\relax }}{12}{figure.caption.4}\protected@file@percent }
\newlabel{fig:r2_mse_5}{{3}{12}{plots of MSE and $R^2$ for the franke function for an error $\epsilon \sim N(0, \sigma ^2)$ with $\sigma =0.2$ and 31 points in each direction\relax }{figure.caption.4}{}}
\newlabel{fig:}{{4a}{12}{$MSE$\relax }{figure.caption.5}{}}
\newlabel{sub@fig:}{{a}{12}{$MSE$\relax }{figure.caption.5}{}}
\newlabel{fig:}{{4b}{12}{$R^2$\relax }{figure.caption.5}{}}
\newlabel{sub@fig:}{{b}{12}{$R^2$\relax }{figure.caption.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces MSE and $R^2$ computed from both the train and test sample\relax }}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fig:train_test}{{4}{12}{MSE and $R^2$ computed from both the train and test sample\relax }{figure.caption.5}{}}
\newlabel{fig:train_test_resample_mse}{{5a}{13}{$MSE$\relax }{figure.caption.6}{}}
\newlabel{sub@fig:train_test_resample_mse}{{a}{13}{$MSE$\relax }{figure.caption.6}{}}
\newlabel{fig:}{{5b}{13}{$R^2$\relax }{figure.caption.6}{}}
\newlabel{sub@fig:}{{b}{13}{$R^2$\relax }{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An average of MSE and $R^2$ computed from both the train and test sample over 100 unique samples\relax }}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:train_test_resample}{{5}{13}{An average of MSE and $R^2$ computed from both the train and test sample over 100 unique samples\relax }{figure.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}OLS variation of $\beta $ paramers}{13}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax }}{14}{figure.caption.7}\protected@file@percent }
\newlabel{fig:beta}{{6}{14}{\relax }{figure.caption.7}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Variance of the $\beta $ parameters for test and train data for a design matrix of polynomial degree 5. Calculated by $Var(\boldsymbol  {\beta }) = diag(\sigma ^2(X^T X)^{-1}$)\relax }}{15}{table.caption.8}\protected@file@percent }
\newlabel{tab:beta}{{1}{15}{Variance of the $\beta $ parameters for test and train data for a design matrix of polynomial degree 5. Calculated by $Var(\boldsymbol {\beta }) = diag(\sigma ^2(X^T X)^{-1}$)\relax }{table.caption.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}OLS bias variance tradeoff}{15}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The bias variance tradeoff for the Franke function using 100 bootstrap iteration together with $n=30$ steps and a noise standard deviation of $\sigma =0.2$\relax }}{16}{figure.caption.9}\protected@file@percent }
\newlabel{fig:bias_variance}{{7}{16}{The bias variance tradeoff for the Franke function using 100 bootstrap iteration together with $n=30$ steps and a noise standard deviation of $\sigma =0.2$\relax }{figure.caption.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The bias variance tradeoff for the Franke function using 100 bootstrap iteration together with $n=100$ steps and a noise standard deviation of $\sigma =0.2$\relax }}{17}{figure.caption.10}\protected@file@percent }
\newlabel{fig:bias_variance_100}{{8}{17}{The bias variance tradeoff for the Franke function using 100 bootstrap iteration together with $n=100$ steps and a noise standard deviation of $\sigma =0.2$\relax }{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}OLS cross validation}{17}{subsubsection.3.1.5}\protected@file@percent }
\newlabel{fig:train_test_resample_mse}{{9a}{17}{5 $k$-folds\relax }{figure.caption.11}{}}
\newlabel{sub@fig:train_test_resample_mse}{{a}{17}{5 $k$-folds\relax }{figure.caption.11}{}}
\newlabel{fig:}{{9b}{17}{10 $k$-folds\relax }{figure.caption.11}{}}
\newlabel{sub@fig:}{{b}{17}{10 $k$-folds\relax }{figure.caption.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A comparison between bootstrap and cross validation for datasets with $n=30$ steps, noise standard deviation $\sigma =0.2$ and 100 bootstrap iterations\relax }}{17}{figure.caption.11}\protected@file@percent }
\newlabel{fig:cv_comp}{{9}{17}{A comparison between bootstrap and cross validation for datasets with $n=30$ steps, noise standard deviation $\sigma =0.2$ and 100 bootstrap iterations\relax }{figure.caption.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A comparison between bootstrap and cross validation for datasets with $n=30$ steps, noise standard deviation $\sigma =0.1$ and 100 bootstrap iterations\relax }}{18}{figure.caption.12}\protected@file@percent }
\newlabel{fig:cv_comp_01}{{10}{18}{A comparison between bootstrap and cross validation for datasets with $n=30$ steps, noise standard deviation $\sigma =0.1$ and 100 bootstrap iterations\relax }{figure.caption.12}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Cross validation to find which polynomial degree gives the lowest MSE for data with $n=30$ steps and noise standard deviation $\sigma =0.2$\relax }}{19}{figure.caption.13}\protected@file@percent }
\newlabel{fig:best_OLS}{{11}{19}{Cross validation to find which polynomial degree gives the lowest MSE for data with $n=30$ steps and noise standard deviation $\sigma =0.2$\relax }{figure.caption.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.6}Ridge and Lasso bias variance tradeoff}{19}{subsubsection.3.1.6}\protected@file@percent }
\newlabel{fig:l_1e-07}{{12a}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-07}{{a}{20}{\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-08}{{12b}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-08}{{b}{20}{\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-09}{{12c}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-09}{{c}{20}{\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-10}{{12d}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-10}{{d}{20}{\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-11}{{12e}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-11}{{e}{20}{\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-12}{{12f}{20}{\relax }{figure.caption.14}{}}
\newlabel{sub@fig:l_1e-12}{{f}{20}{\relax }{figure.caption.14}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Bias variance tradeoff for different choices of lambda using Ridge regression for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }}{20}{figure.caption.14}\protected@file@percent }
\newlabel{fig:ridge_tradeoff}{{12}{20}{Bias variance tradeoff for different choices of lambda using Ridge regression for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }{figure.caption.14}{}}
\newlabel{fig:l_1e-08}{{13a}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-08}{{a}{21}{\relax }{figure.caption.15}{}}
\newlabel{fig:l_1e-09}{{13b}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-09}{{b}{21}{\relax }{figure.caption.15}{}}
\newlabel{fig:l_1e-10}{{13c}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-10}{{c}{21}{\relax }{figure.caption.15}{}}
\newlabel{fig:l_1e-1}{{13d}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-1}{{d}{21}{\relax }{figure.caption.15}{}}
\newlabel{fig:l_1e-12}{{13e}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-12}{{e}{21}{\relax }{figure.caption.15}{}}
\newlabel{fig:l_1e-13}{{13f}{21}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:l_1e-13}{{f}{21}{\relax }{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Bias variance tradeoff for different choices of lambda using Lasso regression for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }}{21}{figure.caption.15}\protected@file@percent }
\newlabel{fig:lasso_tradeoff}{{13}{21}{Bias variance tradeoff for different choices of lambda using Lasso regression for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }{figure.caption.15}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.7}Finding best models}{22}{subsubsection.3.1.7}\protected@file@percent }
\newlabel{fig:}{{14a}{22}{Ridge regression\relax }{figure.caption.16}{}}
\newlabel{sub@fig:}{{a}{22}{Ridge regression\relax }{figure.caption.16}{}}
\newlabel{fig:}{{14b}{22}{Lasso regression\relax }{figure.caption.16}{}}
\newlabel{sub@fig:}{{b}{22}{Lasso regression\relax }{figure.caption.16}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Heatmap of MSE for different choices of polynomial degree and $\lambda $. Here we have used cross validation with 5$k$-folds for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }}{22}{figure.caption.16}\protected@file@percent }
\newlabel{fig:heat_franke}{{14}{22}{Heatmap of MSE for different choices of polynomial degree and $\lambda $. Here we have used cross validation with 5$k$-folds for data with $n=30$ steps and noise standard deviation of $\sigma =0.2$\relax }{figure.caption.16}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Table of best parameters and the following MSE for OLS, Ridge and Lasso regression\relax }}{23}{table.caption.17}\protected@file@percent }
\newlabel{tab:best_comp}{{2}{23}{Table of best parameters and the following MSE for OLS, Ridge and Lasso regression\relax }{table.caption.17}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8}Prediction plots}{23}{subsubsection.3.1.8}\protected@file@percent }
\newlabel{fig:pred_real}{{15a}{24}{Franke function\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_real}{{a}{24}{Franke function\relax }{figure.caption.18}{}}
\newlabel{fig:pred_train}{{15b}{24}{Train data from function data with added noise\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_train}{{b}{24}{Train data from function data with added noise\relax }{figure.caption.18}{}}
\newlabel{fig:pred_test}{{15c}{24}{Test data from function data with added noise\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_test}{{c}{24}{Test data from function data with added noise\relax }{figure.caption.18}{}}
\newlabel{fig:pred_ols}{{15d}{24}{OLS prediction\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_ols}{{d}{24}{OLS prediction\relax }{figure.caption.18}{}}
\newlabel{fig:pred_ridge}{{15e}{24}{Ridge prediction\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_ridge}{{e}{24}{Ridge prediction\relax }{figure.caption.18}{}}
\newlabel{fig:pred_lasso}{{15f}{24}{Lasso prediction\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pred_lasso}{{f}{24}{Lasso prediction\relax }{figure.caption.18}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Plot of the true Franke function together with our train and test data, and our predictions for our optimal parameters shown in table \ref  {tab:best_comp} \relax }}{24}{figure.caption.18}\protected@file@percent }
\newlabel{fig:pred_franke}{{15}{24}{Plot of the true Franke function together with our train and test data, and our predictions for our optimal parameters shown in table \ref {tab:best_comp} \relax }{figure.caption.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Topography data}{25}{subsection.3.2}\protected@file@percent }
\newlabel{fig:}{{16a}{25}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:}{{a}{25}{\relax }{figure.caption.19}{}}
\newlabel{fig:}{{16b}{25}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:}{{b}{25}{\relax }{figure.caption.19}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces MSE and $R^2$ as a function of polynomial degree for OLS predction. Here we are using indexes of [100:141] where every second index are skipped.\relax }}{25}{figure.caption.19}\protected@file@percent }
\newlabel{fig:mse_r2_real}{{16}{25}{MSE and $R^2$ as a function of polynomial degree for OLS predction. Here we are using indexes of [100:141] where every second index are skipped.\relax }{figure.caption.19}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Bias variance tradeoff}{25}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Bias variance tradeoff for the OLS method\relax }}{26}{figure.caption.20}\protected@file@percent }
\newlabel{fig:tradeoff_real}{{17}{26}{Bias variance tradeoff for the OLS method\relax }{figure.caption.20}{}}
\newlabel{fig:}{{18a}{26}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:}{{a}{26}{\relax }{figure.caption.21}{}}
\newlabel{fig:}{{18b}{26}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:}{{b}{26}{\relax }{figure.caption.21}{}}
\newlabel{fig:}{{18c}{26}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:}{{c}{26}{\relax }{figure.caption.21}{}}
\newlabel{fig:}{{18d}{26}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:}{{d}{26}{\relax }{figure.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Bias variance tradeoff for different choices of lambda using Ridge regression\relax }}{26}{figure.caption.21}\protected@file@percent }
\newlabel{fig:ridge_tradeoff_real}{{18}{26}{Bias variance tradeoff for different choices of lambda using Ridge regression\relax }{figure.caption.21}{}}
\newlabel{fig:}{{19a}{27}{\relax }{figure.caption.22}{}}
\newlabel{sub@fig:}{{a}{27}{\relax }{figure.caption.22}{}}
\newlabel{fig:}{{19b}{27}{\relax }{figure.caption.22}{}}
\newlabel{sub@fig:}{{b}{27}{\relax }{figure.caption.22}{}}
\newlabel{fig:}{{19c}{27}{\relax }{figure.caption.22}{}}
\newlabel{sub@fig:}{{c}{27}{\relax }{figure.caption.22}{}}
\newlabel{fig:}{{19d}{27}{\relax }{figure.caption.22}{}}
\newlabel{sub@fig:}{{d}{27}{\relax }{figure.caption.22}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Bias variance tradeoff for different choices of lambda using Ridge regression\relax }}{27}{figure.caption.22}\protected@file@percent }
\newlabel{fig:lasso_tradeoff_real}{{19}{27}{Bias variance tradeoff for different choices of lambda using Ridge regression\relax }{figure.caption.22}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Finding best models}{27}{subsection.3.3}\protected@file@percent }
\newlabel{fig:best_ols_real}{{20a}{28}{OLS\relax }{figure.caption.23}{}}
\newlabel{sub@fig:best_ols_real}{{a}{28}{OLS\relax }{figure.caption.23}{}}
\newlabel{fig:best_ridge_real}{{20b}{28}{Ridge\relax }{figure.caption.23}{}}
\newlabel{sub@fig:best_ridge_real}{{b}{28}{Ridge\relax }{figure.caption.23}{}}
\newlabel{fig:best_lasso_real}{{20c}{28}{Lasso\relax }{figure.caption.23}{}}
\newlabel{sub@fig:best_lasso_real}{{c}{28}{Lasso\relax }{figure.caption.23}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Heatmap of MSE for different choices of polynomial degree and $\lambda $. Here we have used cross validation with 5$k$-folds for data of indexes [100:141] where every second index is skipped\relax }}{28}{figure.caption.23}\protected@file@percent }
\newlabel{fig:heat_real}{{20}{28}{Heatmap of MSE for different choices of polynomial degree and $\lambda $. Here we have used cross validation with 5$k$-folds for data of indexes [100:141] where every second index is skipped\relax }{figure.caption.23}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Table of best parameters and the following MSE for OLS, Ridge and Lasso regression\relax }}{29}{table.caption.24}\protected@file@percent }
\newlabel{tab:best_comp_real}{{3}{29}{Table of best parameters and the following MSE for OLS, Ridge and Lasso regression\relax }{table.caption.24}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Predictions}{29}{subsubsection.3.3.1}\protected@file@percent }
\newlabel{fig:real_pred_real_skip}{{21a}{30}{Full data before split\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_real_skip}{{a}{30}{Full data before split\relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_train_skip}{{21b}{30}{Train data from function data with added noise\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_train_skip}{{b}{30}{Train data from function data with added noise\relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_test_skip}{{21c}{30}{Test data from function data with added noise\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_test_skip}{{c}{30}{Test data from function data with added noise\relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_ols_skip}{{21d}{30}{OLS prediction\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_ols_skip}{{d}{30}{OLS prediction\relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_ridge_skip}{{21e}{30}{Ridge prediction\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_ridge_skip}{{e}{30}{Ridge prediction\relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_lasos_skip}{{21f}{30}{Lasso prediction\relax }{figure.caption.25}{}}
\newlabel{sub@fig:real_pred_lasos_skip}{{f}{30}{Lasso prediction\relax }{figure.caption.25}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Plot of our data together with our train and test data, and our predictions for our optimal parameters shown in table \ref  {tab:best_comp_real} \relax }}{30}{figure.caption.25}\protected@file@percent }
\newlabel{fig:pred_real_skip}{{21}{30}{Plot of our data together with our train and test data, and our predictions for our optimal parameters shown in table \ref {tab:best_comp_real} \relax }{figure.caption.25}{}}
\newlabel{fig:real_pred_real}{{22a}{31}{Full data before split\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_real}{{a}{31}{Full data before split\relax }{figure.caption.26}{}}
\newlabel{fig:real_pred_train}{{22b}{31}{Train data from function data with added noise\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_train}{{b}{31}{Train data from function data with added noise\relax }{figure.caption.26}{}}
\newlabel{fig:real_pred_test}{{22c}{31}{Test data from function data with added noise\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_test}{{c}{31}{Test data from function data with added noise\relax }{figure.caption.26}{}}
\newlabel{fig:real_pred_ols}{{22d}{31}{OLS prediction\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_ols}{{d}{31}{OLS prediction\relax }{figure.caption.26}{}}
\newlabel{fig:real_pred_ridge}{{22e}{31}{Ridge prediction\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_ridge}{{e}{31}{Ridge prediction\relax }{figure.caption.26}{}}
\newlabel{fig:real_pred_lasso}{{22f}{31}{Lasso prediction\relax }{figure.caption.26}{}}
\newlabel{sub@fig:real_pred_lasso}{{f}{31}{Lasso prediction\relax }{figure.caption.26}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Plot of the true Franke function together with our train and test data, and our predictions for our optimal parameters shown in table \ref  {tab:best_comp_real}\relax }}{31}{figure.caption.26}\protected@file@percent }
\newlabel{fig:pred_real}{{22}{31}{Plot of the true Franke function together with our train and test data, and our predictions for our optimal parameters shown in table \ref {tab:best_comp_real}\relax }{figure.caption.26}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{32}{section.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Scaling of data}{32}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Splitting of data and overfitting}{32}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison of bootstrap and cross validation}{33}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Choice of $\lambda $ parameters}{33}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Bias variance tradeoff}{34}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{34}{section.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}}{34}{section.6}\protected@file@percent }
